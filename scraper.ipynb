{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from typing import List, Dict, Tuple\n",
    "import urllib.parse as urlparse\n",
    "import re\n",
    "from random import randint\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_page_url = 'https://data.bopp-obec.info/emis/index.php'\n",
    "# response = requests.get(index_page_url)\n",
    "\n",
    "# with open('index.html', 'w') as f:\n",
    "#   f.write(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('index.html', 'r') as f:\n",
    "#   html_page = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_page, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_for_name(options: List) -> str:\n",
    "  for option in options:\n",
    "    if 'selected' in option.attrs.keys():\n",
    "      return option.get_text()\n",
    "  return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_in_url(url) -> List[Tuple]:\n",
    "  params = url[(url.find('?')+1):]\n",
    "  if not params: return []\n",
    "  params = params.split('&')\n",
    "  params = [tuple(param.split('=', maxsplit=1)) for param in params]\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub('', '', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_select_tag: str = 'จังหวัด/ศธจ.'\n",
    "interested_url_param: str = 'province'\n",
    "all_interested_id: List[Dict] = list()\n",
    "\n",
    "for select_tag_soup in soup.find_all('select'):\n",
    "  options = select_tag_soup.findAll('option')\n",
    "  select_tag_for = select_for_name(options=options)\n",
    "  if select_tag_for != interested_select_tag:\n",
    "    continue\n",
    "\n",
    "  for option in options:\n",
    "    if 'value' not in option.attrs.keys(): continue\n",
    "    if not option.attrs['value']: continue\n",
    "    key_name = re.sub('\\s*\\d+\\s*\\.\\s*', '', option.text)\n",
    "    for key, val in params_in_url(option.attrs['value']):\n",
    "      if key == interested_url_param:\n",
    "        all_interested_id.append({\n",
    "          'name': key_name,\n",
    "          'id': val\n",
    "          })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data_url_format = \\\n",
    "  'https://data.bopp-obec.info/emis/school_edu_p.php?province={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# school_list_index = {}\n",
    "# for item in all_interested_id:\n",
    "#   url = school_data_url_format.format(item['id'])\n",
    "#   response = requests.get(url)\n",
    "#   if response.status_code == 200:\n",
    "#     file_path = 'school_list/' + item['id'] + '.html'\n",
    "#     with open(file_path, 'w') as html_file:\n",
    "#       html_file.write(f'<!-- url: {url} -->\\n')\n",
    "#       html_file.write(f'<!-- scraped: {date.today().isoformat()} -->\\n')\n",
    "#       html_file.write(response.content.decode('utf-8'))\n",
    "#     school_list_index[item['id']] = {\n",
    "#       'name': item['name'],\n",
    "#       'file_path': file_path,\n",
    "#       'updated_at': date.today().isoformat(),\n",
    "#     }\n",
    "#   else: print('status_code not 200', item)\n",
    "\n",
    "# with open('school_list_index.json', 'w') as index_file:\n",
    "#   json.dump(school_list_index, index_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "# with open('school_list_index.json', 'r') as index_file:\n",
    "#   school_list_index = json.load(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SchoolDataIndex:\n",
    "#   def __init__(self,):\n",
    "#     self.dta = {}\n",
    "#     self.load()\n",
    "#     pass\n",
    "\n",
    "#   def load(self):\n",
    "#     with open('school_list_index.json', 'r') as index_file:\n",
    "#       self.data = json.load(index_file)\n",
    "\n",
    "#   def save(self):\n",
    "#     with open('school_list_index.json', 'w') as index_file:\n",
    "#       json.dump(self.data, index_file, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdi = SchoolDataIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_table(table_soup):\n",
    "  thead = table_soup.find('thead')\n",
    "  assert len(thead) > 0\n",
    "  headers = [head.text for head in thead.find_all('th')]\n",
    "  table_data = []\n",
    "  for row in table_soup.find('tbody').find_all('tr'):\n",
    "    row_tds = row.find_all('td')\n",
    "    assert len(row_tds) == len(headers)\n",
    "    row_data = {}\n",
    "    for col, td in zip(headers, row.find_all('td')):\n",
    "      row_data[col.strip()] = td.text.strip()\n",
    "      a_tag = td.find('a')\n",
    "      if a_tag is not None:\n",
    "        row_data['href'] = a_tag.attrs['href']\n",
    "    table_data.append(row_data)\n",
    "  return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def province_school_list(file_path):\n",
    "  with open(file_path, 'r') as file:\n",
    "    soup = BeautifulSoup(file, 'html')\n",
    "\n",
    "  for table in soup.find_all('table'):\n",
    "    if table.find('table'): continue\n",
    "    thead = table.find('thead')\n",
    "    if thead is not None:\n",
    "      break\n",
    "\n",
    "  table_data = parse_table(table)\n",
    "  return table_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in sdi.data:\n",
    "  sdi.data[id]['schools'] = province_school_list(sdi.data[id]['file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdi.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
